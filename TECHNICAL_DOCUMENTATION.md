# The Foundry: Technical Foundation & LLM Onboarding Protocol
**Version:** 3.0
**Date:** 2025-07-05
**Purpose:** This document provides the complete technical context required for a Large Language Model (LLM) to understand, operate, and evolve the Foundry platform. It is the canonical source of truth for the system's architecture, data structures, and operational flow.

---

## 1. System Architecture

The Foundry is a monolithic Flask application designed as a **Cognitive Operating System** for creating, managing, and executing autonomous AI agents called **"Organisms."** The monolithic architecture was chosen for simplicity in this early stage of development, allowing for rapid prototyping and a centralized logic base.

### 1.1. Key Components & Design Rationale

The system is composed of five primary, decoupled Python modules, each with a distinct responsibility. This separation of concerns is a core design principle, intended to make the system more modular and maintainable, even within a monolithic framework.

*   **`app.py` (Web Application & API):**
    *   **Role:** Serves as the primary user interface (UI) and API gateway for the entire system. It handles all external interactions, from a human user managing Organisms via a web browser to programmatic creation and triggering of Organisms.
    *   **Implementation:** A standard Flask application. It uses HTML templates for the UI and provides several key API endpoints:
        *   `/`: Displays all existing Organisms.
        *   `/create`: A web form for manually creating a new Organism.
        *   `/organism/<id>`: Shows the details and run history of a specific Organism.
        *   `/organism/<id>/run`: Manually triggers a run for an Organism.
        *   `/generate_genome`: An API endpoint that accepts a natural language prompt and uses the `genesis` module to return a structured Genome JSON.
    *   **Pre-flight Validator (`validate_genome`):** A crucial function in `app.py` that validates the syntax and structure of every Genome before it is saved to the database. This prevents corrupted or invalid Genomes from entering the system, which is a critical guardrail for system stability.
    *   **Scheduler (`APScheduler`):** The system's autonomic nervous system. It runs as a background process, checking every minute to see if any Organisms are due to run based on their CRON schedules. This was chosen over a simple `while True` loop with `time.sleep()` to provide more robust, reliable, and scalable scheduling.

*   **`engine.py` (The Expression Engine):**
    *   **Role:** The heart of the system, responsible for the execution of Organisms. Its primary function, `run_organism`, interprets a Genome and executes its Genes in sequence.
    *   **Implementation:** The `run_organism` function iterates through the `genes` array of a Genome. For each Gene, it dynamically looks up the corresponding Python function in the `GENE_MAP` from `genes.py` and executes it. It also manages the `data_context`, the dictionary that carries data between Genes.

*   **`genes.py` (The Gene Library):**
    *   **Role:** A library of all the atomic, reusable functions (Genes) that an Organism can execute. Each Gene is a stateless Python function designed to perform a single, well-defined task.
    *   **Implementation:** This file contains the Python function for each Gene and a master `GENE_MAP` dictionary. This map is the central registry that connects the string `type` from a Genome to the actual Python function to be executed.
    *   **Gene Manifests:** Every Gene function's docstring contains a machine-readable `manifest` in YAML format. This is a critical design choice that makes the system self-documenting. The `genesis` module reads these manifests to learn how to use each Gene, allowing the system to be extended simply by adding a new function and its manifest.

*   **`genesis.py` (The AI Genome Generation Module):**
    *   **Role:** Translates high-level, natural language user prompts into low-level, executable Genome JSON.
    *   **Implementation:** It dynamically constructs a detailed system prompt for an LLM. This prompt includes the strict JSON schema for a Genome, a library of all available Genes (generated by parsing the manifests from `genes.py`), and a set of guiding workflow patterns for common tasks. This "prompt engineering" approach allows the LLM to generate complex and effective Genomes without needing to be retrained.

*   **`database.py` (The Cortex / Persistence Layer):**
    *   **Role:** Provides the long-term memory for the system. It stores the definitions of all Organisms, the history of all runs, and the persistent state for each Organism.
    *   **Implementation:**
        *   **SQLite (`foundry_new.db`):** Used for structured data. It was chosen for its simplicity and because it's file-based, requiring no separate database server. It contains three main tables:
            1.  `organisms`: Stores the definition of each Organism (name, Genome JSON, etc.).
            2.  `organism_runs`: A log of every time an Organism is executed.
            3.  `organism_state`: A key-value store for each Organism's persistent memory.
        *   **ChromaDB (`cortex_db/vector_store`):** A vector database used for associative, semantic memory. It stores text embeddings, allowing an Organism to save and query memories based on meaning rather than exact keywords. This was chosen to give Organisms more advanced cognitive capabilities.

---

## 2. Code Structure and Implementation Details

### 2.1. `app.py` - Flask Application and API

The Flask app is the entry point for all interactions.

*   **Asynchronous Execution:** When an Organism run is triggered (either manually or by the scheduler), it is executed in a background thread. This is a critical design decision to prevent long-running Organisms from blocking the web server.
    ```python
    def trigger_run_in_background(organism_id, genome_json):
        """Helper to start a run from any context (manual or scheduled)."""
        with app.app_context(): # Use context to ensure db calls are safe
            run_id = db.create_run(organism_id)
            db.update_organism_last_run(organism_id, datetime.now())

            # Run the organism in a new background thread
            run_thread = threading.Thread(target=run_and_log, args=(genome_json, run_id, organism_id))
            run_thread.start()
            app.logger.info(f"--- Started background run {run_id} for Organism #{organism_id} ---")
    ```
*   **Pre-flight Validator (`validate_genome`):** This function is a series of checks to ensure a Genome is well-formed before it is saved. This prevents runtime errors due to malformed JSON.
    ```python
    def validate_genome(genome_json_str):
        """
        Performs a pre-flight validation of the genome JSON.
        Returns a list of errors if any, otherwise an empty list.
        """
        errors = []
        try:
            genome = json.loads(genome_json_str)
        except json.JSONDecodeError:
            errors.append("Invalid Genome JSON format.")
            return errors

        # ... (checks for name, genes list, trigger, etc.) ...

        if "genes" in genome and isinstance(genome["genes"], list):
            gene_ids = set()
            for i, gene_def in enumerate(genome["genes"]):
                # ... (checks for id, type, config, etc.) ...
                if gene_def["type"] not in GENE_MAP:
                    errors.append(f"Gene '{gene_def.get('id', i)}' uses unknown type '{gene_def['type']}'.")
        return errors
    ```

### 2.2. `engine.py` - The Expression Engine

The `run_organism` function is the core of the execution logic.

*   **Data Context Management:** The `data_context` dictionary is created at the start of a run and is passed through the entire chain of Genes. Each Gene's output is stored in the `data_context`, making it available to subsequent Genes.
*   **Nested Data Context Lookup:** The engine can look up values from nested dictionaries in the `data_context`. This allows for more complex data structures to be passed between Genes.
    ```python
    input_key_path = gene_def.get('input_from')
    if input_key_path:
        # Handle nested lookups
        keys = input_key_path.split('.')
        input_data = data_context
        for key in keys:
            if isinstance(input_data, dict):
                input_data = input_data.get(key)
            else:
                input_data = None
                break
    ```
*   **Conditional Execution (`skip_if`):** The engine supports a `skip_if` key in a Gene definition, which allows for conditional logic in a Genome. This is a simple but powerful feature for creating more dynamic Organisms.
    ```python
    if "skip_if" in gene_def:
        condition_str = gene_def["skip_if"]
        # ... (logic to parse and evaluate the condition) ...
        if actual_value == expected_value:
            print(f"Skipping gene '{gene_def['id']}' due to condition: {condition_str}")
            continue # Skip to the next gene
    ```

### 2.3. `genes.py` - The Gene Library

This file is a collection of all available functions.

*   **`CognitiveConductor` Gene:** A special "recursive" Gene that can take a natural language sub-task, use `genesis` to generate a sub-genome to solve it, and then use `engine` to execute that sub-genome. This allows an Organism to "think" and create its own plans to solve complex problems.
*   **`GenericAPI` Gene:** A universal Gene that can make HTTP requests to any REST API. This is a powerful tool for integrating with external services without needing to write a new Gene for each one.
*   **Gene Manifests:** The YAML manifest in each Gene's docstring is the key to the system's extensibility.
    ```python
    def fetch_reddit_posts(config, input_data=None, data_context=None):
        """
        [GENE] FetchRedditPosts
        description: Fetches recent posts from a specified subreddit.
        config: { 'subreddit': 'name_of_subreddit', 'limit': 25 }
        manifest:
          inputs:
            - name: config.subreddit
              type: string
            - name: config.limit
              type: integer
          outputs:
            - type: list_of_dicts
              keys: ['id', 'title', 'text', 'url']
        """
        # ... (implementation) ...
    ```

### 2.4. `genesis.py` - AI Genome Generation

This module uses an LLM to generate Genomes.

*   **Dynamic System Prompt:** The `generate_genome_from_prompt` function constructs a system prompt by reading the manifests from all available Genes in `genes.py`. This means that when a developer adds a new Gene, `genesis` automatically knows about it and can start using it in the Genomes it generates.
    ```python
    def generate_genome_from_prompt(user_prompt):
        client = OpenAI()

        gene_info_blocks = []
        for gene_name, gene_func in genes.GENE_MAP.items():
            description, manifest = _parse_gene_docstring(gene_func)
            # ... (code to format the gene info into a string) ...
        
        gene_library_str = "\n".join(gene_info_blocks)

        system_prompt = f"""
        You are a specialized AI assistant called Genesis...
        
        You have access to the following Gene Library:
        {gene_library_str}
        """
        # ... (call to the LLM) ...
    ```

### 2.5. `database.py` - The Cortex

This module handles all data persistence.

*   **SQLite Schema:**
    *   `organisms`: `id`, `name`, `genome_json`, `created_timestamp`, `last_run_timestamp`
    *   `organism_runs`: `id`, `organism_id`, `status`, `log_output`, `started_timestamp`, `finished_timestamp`
    *   `organism_state`: `organism_id`, `key`, `value` (a generic key-value store for each Organism)
*   **ChromaDB Integration:** The `save_memory` and `query_memory` functions provide an interface to the ChromaDB vector store. This allows Organisms to have a semantic, long-term memory.
    ```python
    def save_memory(organism_id, memory_text):
        """Saves a piece of text to an Organism's associative memory."""
        memory_id = f"{organism_id}_{hash(memory_text)}"
        memory_collection.add(
            documents=[memory_text],
            metadatas=[{"organism_id": organism_id}],
            ids=[memory_id]
        )
        return memory_id

    def query_memory(organism_id, query_text, n_results=3):
        """Queries an Organism's associative memory and returns the most similar results."""
        results = memory_collection.query(
            query_texts=[query_text],
            n_results=n_results,
            where={"organism_id": str(organism_id)} # Filter memories by organism
        )
        return results['documents'][0] if results['documents'] else []
    ```

---

## 3. Data Flow and `data_context`

The `data_context` is a Python dictionary that acts as the "bloodstream" for an Organism run, carrying data from one Gene to the next.

1.  **Initialization:** The `data_context` is created as an empty dictionary at the beginning of a run. If an `initial_input` is provided, it is placed in the context under the key `"initial_input"`.
2.  **Execution & Data Transfer:**
    *   For each Gene, the `engine` reads the `input_from` key to determine which value from the `data_context` to use as the input for the current Gene.
    *   The Gene function is executed.
    *   The return value of the Gene is stored back into the `data_context`. The key used for storage is defined by the `output_as` key in the Gene definition (or defaults to the Gene's `id`).
3.  **Termination:** This process repeats for all Genes. The final `data_context` contains the results of all the steps in the Genome.

---

## 4. Core Data Structures

### 4.1. The Genome (`.json`)

The Genome is the declarative blueprint for an Organism.

```json
{
  "name": "organism_name_string",
  "trigger": {
    "type": "schedule",
    "cron": "*/5 * * * *"
  },
  "genes": [
    {
      "id": "unique_string_id_for_this_step",
      "type": "GeneTypeStringFromGeneMap",
      "config": { "param1": "value1" },
      "input_from": "key_in_data_context",
      "output_as": "new_key_for_data_context",
      "skip_if": "some_context_key==some_value"
    }
  ]
}
```

### 4.2. The Gene Manifest (in `genes.py` docstrings)

The manifest is a machine-readable description of a Gene's interface.

```yaml
# Inside a Python function's docstring in genes.py
"""
description: A human-readable explanation of the gene's purpose.
manifest:
  inputs:
    - name: input_data
      type: list_of_dicts
      keys: ['id', 'title']
    - name: config.parameter_name
      type: string
  outputs:
    - type: list_of_dicts
      keys: ['id', 'title', 'new_field']
"""
```

---

## 5. Integration Patterns

*   **External APIs:** The `GenericAPI` gene is the primary mechanism for integrating with external services. It can be configured to make GET, POST, PUT, or DELETE requests to any REST API, with support for headers, query parameters, and JSON bodies.
*   **File System:** The `ExecuteInRuntime` gene can be used to interact with the local file system by executing shell commands like `ls`, `cat`, or `echo`.

---

## 6. Technical Dependencies

The following are the key dependencies from `requirements.txt` and their purpose in the system:

*   **`Flask`**: The core web framework used for the UI and API.
*   **`Flask-APScheduler`**: Manages the CRON-based scheduling of Organisms.
*   **`praw`**: The Python Reddit API Wrapper, used by the `FetchRedditPosts` gene.
*   **`vaderSentiment`**: A sentiment analysis library used by the `AnalyzeSentiment` gene.
*   **`python-dotenv`**: Used to load environment variables from a `.env` file, which is how API keys and other secrets are managed.
*   **`openai`**: The official OpenAI Python client, used by `genesis` to generate Genomes and by `SummarizeArticles` to summarize text.
*   **`croniter`**: A library for parsing and evaluating CRON expressions, used by the scheduler.
*   **`pyyaml`**: Used to parse the YAML manifests in the Gene docstrings.
*   **`chromadb`**: The client library for the ChromaDB vector database, used for long-term semantic memory.
*   **`sentence-transformers`**: Used by ChromaDB to generate the embeddings for the text that is stored in the vector memory.
*   **`requests`**: A general-purpose HTTP library used by `PostToSlack`, `FetchNewsAPI`, and `GenericAPI`.

---

## 7. Error Handling

*   **Pre-flight Validation:** The `validate_genome` function in `app.py` catches structural errors in Genomes before they are saved.
*   **Engine-level Error Handling:** The `run_organism` function in `engine.py` has a `try...except` block that catches any exceptions that occur during the execution of a Gene. If a Gene fails, the run is marked as "failed" and the error is logged to the database.
*   **Gene-level Error Handling:** Individual Genes are responsible for handling their own specific errors (e.g., API connection errors, missing keys in input data) and raising exceptions when they cannot proceed.
